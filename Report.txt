| **Thư viện                                | **Chức năng chính**                                       | **Ứng dụng trong project**                                                                                                                                                             |
| ----------------------------------------- | --------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenCV (cv2)**                          | Xử lý ảnh và video theo thời gian thực.                   | Dùng để truy cập webcam, đọc khung hình, chuyển đổi màu RGB ↔ BGR, vẽ landmarks bàn tay, hiển thị khung hình và thông tin dự đoán trong cửa sổ real-time.                              |
| **MediaPipe (mediapipe.solutions.hands)** | Framework nhận diện bàn tay, khuôn mặt, pose.             | Dùng để **phát hiện và trích xuất 21 điểm mốc (landmarks)** của mỗi bàn tay trong từng khung hình. Các điểm này được dùng làm đặc trưng đầu vào cho mô hình học máy.                   |
| **NumPy (np)**                            | Xử lý mảng số học, thao tác dữ liệu vector/matrix.        | Lưu trữ, chuẩn hóa, nối, và thao tác với dữ liệu landmark. Dùng để tính toán toạ độ tương đối, khoảng cách chuẩn hoá và lưu dữ liệu thành file `.npy`.                                 |
| **scikit-learn (sklearn)**                | Cung cấp các mô hình học máy và công cụ xử lý dữ liệu.    | Sử dụng **KNeighborsClassifier** để huấn luyện mô hình phân loại cử chỉ; **StandardScaler** để chuẩn hóa dữ liệu đầu vào; **train_test_split** để chia dữ liệu huấn luyện và kiểm thử. |
| **joblib**                                | Lưu và tải các mô hình học máy (model persistence).       | Dùng để **lưu mô hình KNN và bộ scaler** sau khi huấn luyện vào file `.joblib` để tái sử dụng trong quá trình nhận diện real-time.                                                     |
| **argparse, os, warnings**                | Quản lý tham số dòng lệnh, kiểm tra file, xử lý cảnh báo. | Hỗ trợ kiểm tra sự tồn tại của dữ liệu, đường dẫn lưu model và ẩn các cảnh báo không cần thiết.                                                                                        |
| **ipywidgets, IPython.display**           | Tạo giao diện tương tác trong Jupyter Notebook.           | Cho phép lựa chọn nhãn cử chỉ cần thu thập và hiển thị số lượng mẫu đã có, giúp việc thu thập dữ liệu trở nên trực quan hơn.                                                           |


Quá trình triển khai được chia thành ba giai đoạn chính, tương ứng với ba chế độ trong chương trình: Collect – Train – Predict.

1. Collect Mode (Thu thập dữ liệu)
    - Camera được kích hoạt bằng OpenCV để thu hình ảnh bàn tay người dùng.
    - MediaPipe Hands trích xuất 21 điểm landmark (x, y, z) cho mỗi bàn tay (tối đa 2 tay).
    - Các toạ độ được chuẩn hoá (đưa gốc về cổ tay, chia cho khoảng cách lớn nhất) → tạo vector đặc trưng cố định kích thước.
    - Mỗi mẫu thu thập gồm cặp (label, vector đặc trưng) và được lưu vào file landmarks.npy.

b. Train Mode (Huấn luyện mô hình)
    - Dữ liệu từ landmarks.npy được tải và chia thành train/test (80/20).
    - Dùng StandardScaler để chuẩn hóa dữ liệu, tránh lệch thang đo giữa các đặc trưng.
    - Áp dụng mô hình K-Nearest Neighbors (KNN) để huấn luyện, do dữ liệu không lớn và đặc trưng đã được rút trích tốt.
    - Sau huấn luyện, mô hình và scaler được lưu thành knn_model.joblib và scaler.joblib.

c. Predict Mode (Nhận diện real-time)
    - Chạy webcam, dùng MediaPipe để nhận diện bàn tay và lấy landmark mỗi frame.
    - Chuẩn hoá vector đầu vào bằng scaler, sau đó đưa vào mô hình KNN để dự đoán cử chỉ.
    - Kết quả được hiển thị trực tiếp trên màn hình với label dự đoán và độ tin cậy (%).

