Hand Gesture Recognition (MediaPipe + scikit-learn)
====================================================

This project captures hand landmarks using MediaPipe and trains a lightweight scikit-learn classifier (RandomForest) to recognize gestures in real-time.

Quick steps:
1. Collect data for each gesture:
   python src/collect_dataset.py --label gesture_0 --out data/landmarks.csv
   (Repeat for gesture_1 ... gesture_5 and append to same CSV)

2. Train model:
   python src/train_model.py --in data/landmarks.csv --out models/gesture_clf.joblib

3. Run real-time detection:
   python src/detect_gesture.py --model models/gesture_clf.joblib

Controls:
- collect_dataset: press 's' to save sample, 'q' to quit
- detect_gesture: press 'q' to quit

Requirements:
- Python 3.9 recommended
- Install dependencies: pip install -r requirements.txt


STT	TÃªn label (dÃ¹ng trong code)	MÃ´ táº£ cá»­ chá»‰	Gá»£i Ã½ khi thu máº«u
1ï¸âƒ£	thumbs_up	ğŸ‘ NgÃ³n cÃ¡i giÆ¡ lÃªn (like)	Tay hÆ°á»›ng vá» camera, ngÃ³n cÃ¡i lÃªn rÃµ
2ï¸âƒ£	thumbs_down	ğŸ‘ NgÃ³n cÃ¡i chá»‰ xuá»‘ng	Giá»‘ng like nhÆ°ng xoay ngÆ°á»£c tay
3ï¸âƒ£	fist	âœŠ Náº¯m tay láº¡i	Giá»¯ bÃ n tay náº¯m cháº·t, khÃ´ng duá»—i ngÃ³n
4ï¸âƒ£	open_hand	ğŸ–ï¸ BÃ n tay má»Ÿ, cÃ¡c ngÃ³n duá»—i	Tay má»Ÿ tháº³ng, lÃ²ng bÃ n tay hÆ°á»›ng vÃ o camera
5ï¸âƒ£	peace	âœŒï¸ GiÆ¡ 2 ngÃ³n (index + middle)	Hai ngÃ³n tÃ¡ch nhau, hÆ°á»›ng vá» camera
6ï¸âƒ£	okay	ğŸ‘Œ NgÃ³n cÃ¡i vÃ  ngÃ³n trá» cháº¡m nhau thÃ nh vÃ²ng trÃ²n	Giá»¯ á»•n Ä‘á»‹nh, camera tháº¥y rÃµ hÃ¬nh trÃ²n